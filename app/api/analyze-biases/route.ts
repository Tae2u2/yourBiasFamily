// app/api/analyze-biases/route.ts
// Next.js API Route for AI Analysis using Claude Haiku 3

import Anthropic from '@anthropic-ai/sdk';
import { NextRequest, NextResponse } from 'next/server';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

interface Bias {
  name: string;
  reason: string;
  startDate: string;
  endDate: string;
}

export async function POST(request: NextRequest) {
  try {
    const { biases }: { biases: Bias[] } = await request.json();

    if (!biases || biases.length < 2) {
      return NextResponse.json(
        { error: 'ìµœì• ë¥¼ 2ëª… ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.' },
        { status: 400 }
      );
    }

    // Claude Haiku 3ë¡œ ë¶„ì„ (ê°€ì¥ ì €ë ´: $0.25 input, $1.25 output per M tokens)
    const message = await anthropic.messages.create({
      model: 'claude-haiku-3-20240307',
      max_tokens: 800,
      messages: [
        {
          role: 'user',
          content: `ë‹¤ìŒ ìµœì• ë“¤ì˜ ê³µí†µì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

${biases.map((b, idx) => `
${idx + 1}. ${b.name}
   - ì…ë• ê³„ê¸°: ${b.reason}
   - ì¢‹ì•„í–ˆë˜ ê¸°ê°„: ${b.startDate} ~ ${b.endDate}
`).join('\n')}

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
  "commonalities": [ê³µí†µì  3ê°€ì§€ë¥¼ ë°°ì—´ë¡œ],
  "familyCrest": "ì´ ì‚¬ëŒì˜ ì·¨í–¥ì„ ë‚˜íƒ€ë‚´ëŠ” ê°€ë¬¸ ì´ë¦„ (ì˜ˆ: âšœï¸ æ·¸ç´”é­…åŠ›å®¶é–€ âšœï¸)",
  "narrative": "ì¡±ë³´ í•´ì„¤ (200ì ì´ë‚´, ì¤‘ì„¸ ê·€ì¡± ì–´íˆ¬ë¡œ ì‘ì„±)"
}

ì¤‘ìš”: ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.`,
        },
      ],
    });

    const responseText = message.content[0].type === 'text' 
      ? message.content[0].text 
      : '';

    // JSON íŒŒì‹±
    const jsonMatch = responseText.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      throw new Error('Invalid response format');
    }

    const analysis = JSON.parse(jsonMatch[0]);

    // ì‚¬ìš©ëŸ‰ ë¡œê¹… (ë¹„ìš© ì¶”ì )
    const inputTokens = message.usage.input_tokens;
    const outputTokens = message.usage.output_tokens;
    const estimatedCost = (inputTokens * 0.25 / 1_000_000) + (outputTokens * 1.25 / 1_000_000);

    console.log(`
      ğŸ¤– AI Analysis Complete
      ğŸ“Š Tokens: ${inputTokens} in, ${outputTokens} out
      ğŸ’° Cost: $${estimatedCost.toFixed(6)} (~${Math.round(estimatedCost * 1300)}ì›)
    `);

    return NextResponse.json({
      ...analysis,
      metadata: {
        inputTokens,
        outputTokens,
        estimatedCostUSD: estimatedCost,
        estimatedCostKRW: Math.round(estimatedCost * 1300),
      },
    });

  } catch (error) {
    console.error('AI Analysis Error:', error);
    return NextResponse.json(
      { error: 'AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.' },
      { status: 500 }
    );
  }
}

// ë¹„ìš© ìµœì í™” íŒ:
// 1. Prompt Caching ì‚¬ìš© ì‹œ 90% ì ˆê° ê°€ëŠ¥
// 2. Batch API ì‚¬ìš© ì‹œ 50% ì ˆê° ê°€ëŠ¥  
// 3. ì—¬ëŸ¬ ìš”ì²­ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸° (batching)
// 4. ìµœëŒ€ í† í° ìˆ˜ ì œí•œìœ¼ë¡œ ë¹„ìš© í†µì œ

/* 
ì˜ˆìƒ ë¹„ìš© (Claude Haiku 3):
- Input: ~375 tokens Ã— $0.25/M = $0.000094
- Output: ~650 tokens Ã— $1.25/M = $0.000813
- Total: ~$0.001 (ì•½ 1.3ì›)

ì›” 10,000ê±´ ì²˜ë¦¬ ì‹œ:
- ì´ ë¹„ìš©: $10 (ì•½ 13,000ì›)
- ê´‘ê³  ìˆ˜ìµìœ¼ë¡œ ì¶©ë¶„íˆ ì»¤ë²„ ê°€ëŠ¥!
*/
